<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>B.H.Ai Life - NEOBLADE yt</title>
    <script defer src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.js"></script>
    <style>
        :root { --neon: #00f2ff; --bg: #050508; }
        body { background: var(--bg); color: white; font-family: 'Courier New', monospace; text-align: center; margin: 0; padding: 10px; overflow-x: hidden; }
        
        /* THE AI FACE ENGINE */
        .ai-face-container { height: 180px; display: flex; justify-content: center; align-items: center; position: relative; }
        .eye-outer { width: 100px; height: 100px; border: 4px solid var(--neon); border-radius: 50%; display: flex; justify-content: center; align-items: center; box-shadow: 0 0 20px var(--neon); transition: 0.3s; }
        .eye-inner { width: 40px; height: 40px; background: var(--neon); border-radius: 50%; box-shadow: 0 0 30px var(--neon); }
        
        /* Animation Classes */
        .speaking { animation: pulse 0.4s infinite alternate; }
        @keyframes pulse { 
            0% { transform: scale(1); box-shadow: 0 0 20px var(--neon); } 
            100% { transform: scale(1.2); box-shadow: 0 0 50px var(--neon); } 
        }
        .blinking { animation: blink 4s infinite; }
        @keyframes blink { 0%, 90%, 100% { height: 40px; } 95% { height: 2px; } }

        /* VISION & CAMERA */
        .vision-box { width: 120px; height: 90px; border: 1px solid #333; position: fixed; top: 10px; right: 10px; border-radius: 10px; overflow: hidden; opacity: 0.7; }
        #video { width: 100%; height: 100%; object-fit: cover; transform: scaleX(-1); }

        .controls { background: #11111a; padding: 20px; border-radius: 20px; border-top: 2px solid var(--neon); margin-top: 10px; }
        #ai-text { min-height: 60px; font-size: 0.9rem; margin-bottom: 15px; border-left: 3px solid var(--neon); padding-left: 10px; text-align: left; }
        .btn { width: 100%; padding: 18px; border-radius: 12px; border: none; font-weight: bold; font-size: 1.1rem; cursor: pointer; }
        .btn-mic { background: var(--neon); color: black; transition: 0.2s; }
        .btn-mic:active { transform: scale(0.9); }
    </style>
</head>
<body>

    <div class="vision-box">
        <video id="video" autoplay muted playsinline></video>
        <div style="position:absolute; bottom:0; width:100%; background:rgba(0,0,0,0.5); font-size:8px;" id="id-tag">SCANNING...</div>
    </div>

    <div class="ai-face-container">
        <div class="eye-outer" id="mainEye">
            <div class="eye-inner blinking" id="pupil"></div>
        </div>
    </div>

    <h2 style="color:var(--neon); margin:0;">B.H.Ai</h2>
    <p style="font-size: 10px; margin-bottom: 20px;">READY FOR NEOBLADE yt</p>

    <div class="controls">
        <div id="ai-text">B.H.Ai: Systems stabilized. User recognition active.</div>
        <button class="btn btn-mic" id="micBtn">üéôÔ∏è COMMAND</button>
        <button class="btn" style="background:#222; color:#777; margin-top:10px; font-size: 0.8rem;" onclick="location.reload()">REBOOT SYSTEM</button>
    </div>

<script>
    const API_KEY = "AIzaSyCIqlIQSaYgwFsa6c4gXI9tuK_YTissn5Y";
    const mainEye = document.getElementById('mainEye');
    const pupil = document.getElementById('pupil');
    const aiText = document.getElementById('ai-text');
    const idTag = document.getElementById('id-tag');

    // 1. FACE RECOGNITION (Vision)
    async function initVision() {
        const MODEL_URL = 'https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights';
        await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "user" } });
        document.getElementById('video').srcObject = stream;
        
        setInterval(async () => {
            const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());
            if(detections.length > 0) {
                idTag.innerText = "USER: NEOBLADE yt";
                idTag.style.color = "#00ff00";
            } else {
                idTag.innerText = "SCANNING...";
                idTag.style.color = "white";
            }
        }, 1000);
    }

    // 2. INTELLIGENCE & VOICE
    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    
    document.getElementById('micBtn').onclick = () => {
        recognition.start();
        aiText.innerText = "Listening...";
    };

    recognition.onresult = async (event) => {
        const userSpeech = event.results[0][0].transcript;
        aiText.innerText = "You: " + userSpeech;
        
        const response = await fetch(`https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent?key=${API_KEY}`, {
            method: 'POST',
            body: JSON.stringify({ contents: [{ parts: [{ text: "You are B.H.Ai. Briefly help NEOBLADE yt with: " + userSpeech }] }] })
        });
        
        const data = await response.json();
        const msg = data.candidates[0].content.parts[0].text;
        
        aiText.innerText = "B.H.Ai: " + msg;
        speak(msg);
    };

    function speak(text) {
        const synth = window.speechSynthesis;
        const utter = new SpeechSynthesisUtterance(text);
        
        // EYE ANIMATION SYNC
        utter.onstart = () => {
            mainEye.classList.add('speaking');
            pupil.classList.remove('blinking');
        };
        utter.onend = () => {
            mainEye.classList.remove('speaking');
            pupil.classList.add('blinking');
        };
        
        synth.speak(utter);
    }

    initVision();
</script>
</body>
            </html>
                                                       
