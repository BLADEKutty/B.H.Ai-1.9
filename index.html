<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Bhai - Lens & Voice Agent</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <style>
        :root { --neon: #00f2ff; --bg: #05050a; }
        body { background: var(--bg); color: white; font-family: 'Segoe UI', sans-serif; margin: 0; text-align: center; overflow: hidden; }
        
        /* THE BHAI "LENS" VIEW */
        #lens-container { position: relative; width: 100vw; height: 60vh; background: #000; border-bottom: 3px solid var(--neon); }
        #video { width: 100%; height: 100%; object-fit: cover; }
        #canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }
        
        /* SCANNING INTERFACE */
        .scan-line { position: absolute; top: 0; width: 100%; height: 4px; background: var(--neon); box-shadow: 0 0 20px var(--neon); animation: scan 3s infinite linear; opacity: 0.5; }
        @keyframes scan { 0% { top: 0; } 100% { top: 100%; } }

        .dashboard { padding: 20px; background: #0a0a15; height: 40vh; }
        #ai-status { font-size: 0.7rem; color: var(--neon); letter-spacing: 2px; margin-bottom: 10px; }
        #ai-log { font-size: 1.1rem; border-left: 3px solid var(--neon); padding-left: 15px; text-align: left; min-height: 80px; }
        .bhai-orb { width: 60px; height: 60px; background: var(--neon); border-radius: 50%; margin: 10px auto; box-shadow: 0 0 30px var(--neon); }
        .active { animation: pulse 0.5s infinite alternate; }
        @keyframes pulse { from { transform: scale(1); } to { transform: scale(1.2); } }
    </style>
</head>
<body>

<div id="lens-container">
    <video id="video" autoplay muted playsinline></video>
    <canvas id="canvas"></canvas>
    <div class="scan-line"></div>
</div>

<div class="dashboard">
    <div id="ai-status">SYSTEMS ONLINE | WAKE-WORD: "BHAI"</div>
    <div class="bhai-orb" id="orb"></div>
    <div id="ai-log">Bhai: I am watching. Say "Bhai" and show me something to identify.</div>
</div>

<script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const aiLog = document.getElementById('ai-log');
    const orb = document.getElementById('orb');
    let lensModel;

    // 1. VOICE ACTIVATION (The "Bhai" Wake-word)
    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.continuous = true;
    recognition.lang = 'en-US';

    recognition.onresult = (event) => {
        const speech = event.results[event.results.length - 1][0].transcript.toLowerCase();
        console.log("Heard:", speech);

        if (speech.includes("bhai") || speech.includes("bh ai")) {
            activateBhai(speech);
        }
    };

    function activateBhai(speech) {
        orb.classList.add('active');
        aiLog.innerText = "Bhai: Yes, NEOBLADE? I'm listening.";
        
        // Intelligent Action Mapping
        if(speech.includes("search")) {
            const query = speech.split("search")[1];
            window.open(`https://www.google.com/search?q=${query}`);
        } else if(speech.includes("youtube") || speech.includes("channel")) {
            window.open("https://studio.youtube.com");
            respond("Opening your channel dashboard now.");
        } else if(speech.includes("what is this") || speech.includes("look")) {
            scanObject();
        }
    }

    // 2. BHAI LENS (Google Lens-style recognition)
    async function initLens() {
        lensModel = await cocoSsd.load();
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
        video.srcObject = stream;
        detectFrame();
    }

    async function detectFrame() {
        const predictions = await lensModel.detect(video);
        drawPredictions(predictions);
        requestAnimationFrame(detectFrame);
    }

    function drawPredictions(predictions) {
        const ctx = canvas.getContext('2d');
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        predictions.forEach(p => {
            ctx.strokeStyle = "#00f2ff";
            ctx.lineWidth = 4;
            ctx.strokeRect(...p.bbox);
            ctx.fillStyle = "#00f2ff";
            ctx.fillText(p.class.toUpperCase(), p.bbox[0], p.bbox[1] > 10 ? p.bbox[1] - 5 : 10);
        });
    }

    async function scanObject() {
        const predictions = await lensModel.detect(video);
        if(predictions.length > 0) {
            const item = predictions[0].class;
            respond(`I see a ${item}. Should I search for more details on this?`);
            window.open(`https://www.google.com/search?q=${item}`);
        } else {
            respond("I can't clearly see the object. Move closer.");
        }
    }

    function respond(text) {
        aiLog.innerText = "Bhai: " + text;
        const utter = new SpeechSynthesisUtterance(text);
        utter.onend = () => orb.classList.remove('active');
        window.speechSynthesis.speak(utter);
    }

    window.onload = () => {
        initLens();
        recognition.start();
    };
</script>
</body>
</html>
